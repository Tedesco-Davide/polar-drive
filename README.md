### PolarDrive ğŸš—â„ï¸

Repository unificato per il progetto **PolarDrive**.

---

## âš™ï¸ Comandi

### ğŸ”· FRONTEND GENERICO

_(Tasto destro sulla cartella `frontend` â†’ Open in integrated Terminal)_

- `npm run dev` â†’ Avvio classico in dev
- `npm lista` â†’ Visualizza tutti i pacchetti installati
- `npm i` â†’ Reinstalla tutti i pacchetti

---

### ğŸ”¶ BACKEND GENERICO

_(Tasto destro sulla cartella `backend` â†’ Open in integrated Terminal)_

- `dotnet build` â†’ Rebuild completo della soluzione
- `dotnet run --project PolarDriveInitDB.Cli` â†’ Crea un nuovo DB da zero nella cartella `PolarDriveInitDB.Cli`
- `dotnet run --project PolarDriveInitDBMockData.Cli` â†’ Aggiunge dati di mock al DB creato
- `dotnet run --project PolarDrive.WebApi` â†’ Avvia la WebAPI principale

---

### ğŸ§  BACKEND MISTRAL AI

_(Tasto destro sulla cartella `backend/PolarDrive.WebApi` â†’ Open in integrated Terminal)_

#### âœ… Ollama

- `ollama --version` â†’ Mostra la versione del runtime **Ollama**
  > Ollama Ã¨ il **motore AI locale**: scarica, avvia e gestisce modelli LLM direttamente sul tuo PC.

#### ğŸ§ª DEBUG LOCALE (opzionale)

- `ollama run mistral` â†’ Esegue **Mistral** in modalitÃ  chat interattiva (terminal-based)
  > âš ï¸ Solo per test manuali: non adatto allâ€™uso via codice .NET.

#### âœ… UTILIZZO CORRETTO IN BACKEND

- `ollama serve` â†’ Avvia **Ollama in modalitÃ  server REST**
  > Espone l'endpoint `http://localhost:11434/api/generate` per richieste AI programmatiche.  
  > âœ”ï¸ Ãˆ **stateless** e perfettamente integrabile nel backend (`HttpClient`, `POST`, JSON).
